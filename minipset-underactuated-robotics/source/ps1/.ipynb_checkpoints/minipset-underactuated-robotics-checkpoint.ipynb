{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "jupyter",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Mini Problem Set – Trajectory Optimization for Under-actuated Robots\n",
    "\n",
    "### Due May 10, 2017 at 23:59:59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "import_notice",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Be sure to load the modules below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "imports",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import scipy.linalg\n",
    "from numpy import matrix\n",
    "from IPython.display import YouTubeVideo, HTML\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "manual_gains_title",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## Part 1 - Manual Control Gains (x points)\n",
    "\n",
    "In this problem set, you will learn to control the cart-pole, a simple underactuated system that illustrates the process of solving and the methods required to control underactuated systems.\n",
    "\n",
    "The cart-pole is a classic control problem, as the dynamics of the system are relatively straightforward, but the control of the cart-pole is inherently complex due its under-actuated nature. Remember from lecture that “under-actuated” is another way of saying that there are less controllable actuators than there are degrees of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## The Cart-Pole\n",
    "\n",
    "Below, you will implement the control system for the cart-pole, the canonical underactuated system. See the figure below for an idea of what this system looks. \n",
    "\n",
    "![](images/cart-pole.png)\n",
    "<emph>a cart with a pendulum (the pole) attached to it. The cart is constrained to lateral movement, and the objective is to balance the pendulum at the top of the cart. Describe what the degrees of freedom are</emph>\n",
    "\n",
    "As you saw in lecture, the cart-pole is a system with two degrees of freedom, but only one degree of freedom is actuated. Therefore, this system is under-actuated.  \n",
    "Here, we show the cart-pole system in free-fall, with no actuated control. As you can see, the system is unstable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "free-fall-video",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\t<video width=\"620\" height=\"420\" controls>\n",
       "\t  <source src=\"./media/trimmed_freefall.mp4\" type=\"video/mp4\">\n",
       "\t</video>\n",
       "\t"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_local_video('trimmed_freefall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "end_intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "You will learn how to stabilize the pendulum by controlling the cart’s lateral movement. The goal of this problem is to reach a stable final state, in which the pendulum is perfectly balanced on above of the cart’s center of mass at its initial starting position on the x axis, after starting from any initial state. \n",
    "You will implement helper functions and adjust the control parameters of the system.\n",
    "Just a note, the coordinate system we’re using here is different from the cart-pole demo presented in lecture. In our problem set, our unstable equilibrium state with the pole centered at the top of the cart is $\\theta = 0$, while the pole centered below the cart is $\\theta = \\pi$. $\\theta$ is positive in the clockwise direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "manual_gains_text",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Manually Find the Control Gains (K Matrix) (15 points):\n",
    "\n",
    "As we saw in the free-fall video, balancing the pendulum at the top of the cart’s center of mass is an unstable equilibrium. Any perturbation to the cart-pole system will move the pendulum away from this unstable equilibrium point. \n",
    "\n",
    "We must therefore devise a control system that drives the pendulum to its point of unstable equilibrium, and stabilizes the pendulum on top of the cart. \n",
    "\n",
    "To accomplish this, we will use a closed loop full state feedback controller. \n",
    "\n",
    "We will explain the feedback controller as follows:\n",
    "\n",
    "Our state vector for the system is $[x, dx, \\theta, d\\theta]$ (note that this is configured differently from the lecture Matlab demo vector). This state vector is multiplied by a feedback gain of -K and fed back as the input force to the side of the cart in the positive x direction, such that $u = -Kx$.\n",
    "\n",
    "In this section, you will use a tried and true method for finding the K matrix - you will tune the matrix by hand. Play around with the K matrix values until you find a gain vector K that successfully keeps the pole upright.\n",
    "\n",
    "You can learn in depth about the theory behind the feedback controller from [these notes](https://ocw.mit.edu/courses/aeronautics-and-astronautics/16-30-feedback-control-systems-fall-2010/lecture-notes/MIT16_30F10_lec11.pdf), but don’t spend too much time on this section. The main goal here is to provide an intuition for what the K gain matrix represents, and how manipulating the matrix leads to control over the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "set_manual_gains",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def manualGains():\n",
    "    \"\"\"\n",
    "    Try setting different values for K matrix and \n",
    "    running the next cell to see the resulting behaviour\n",
    "\n",
    "    The resulting plot shows the x (red trace) and theta (green trace) displacement over time. \n",
    "    \"\"\"\n",
    "    manual_K = matrix([[0., 0., 0., 0.]])\n",
    "    ### BEGIN SOLUTION\n",
    "    # A good example of for a K that stabilizes the system is \n",
    "    manual_K = matrix([[0., -2, -40., -7.]])\n",
    "    ### END SOLUTION    \n",
    "    return manual_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "manual_gains_test",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9c601ee4eaf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmanualGains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcontrol_with_manual_gain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/ericmanzi/Desktop/6.834/underactuated_robotics/minipset-underactuated-robotics/source/ps1/utils.py\u001b[0m in \u001b[0;36mcontrol_with_manual_gain\u001b[0;34m(K_in)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mglobal\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mfinal_pose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdx_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdth_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"manual_K\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtest_end_close_to_goal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_pose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mtest_ok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_0' is not defined"
     ]
    }
   ],
   "source": [
    "K = manualGains()\n",
    "control_with_manual_gain(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have successfully controlled the behaviour of the system using a simple hand-tuned gain matrix. Unfortunately, in most real system the number of possible states increases, and it can be very hard to build an intuition on how the K matrix will affect the the control system behaviour. Also, hand-tuned gains are not necessarily optimal. \n",
    "\n",
    "Fortunately, we live in the 21st century where we can have computers run algorithms that solve these type of problems quite nicely. This is where the next section comes into play - we will use the linear quadratic regulator (LQR) to compute the optimal feedback gain K matrix!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Optimally find the Control Gains using LQR (40 points total):\n",
    "\n",
    "Using LQR, we will pose the control problem as an optimization problem in which we aim to minimize a cost function that is a combination of a current state cost, an input cost, and (optionally) a final state cost. LQR is guaranteed to find the optimal solution for the cost function provided. \n",
    "\n",
    "The only problem, is that as LQR’s name might already give away, it requires the system to be linear. The cart-pole system, on the other hand, is non-linear. So how do we use LQR to optimize the controls for our system? By linearizing the system!\n",
    "\n",
    "Linearization of the system is taken care of by understanding the dynamics of the systems, using Taylor expansions on those dynamics, and taking the first order parts of the Taylor expansions as the linearization. These are the first order Taylor expansions of the manipulator equations we briefly explored in lecture. Don’t worry, you won’t have to derive the dynamics yourself for this mini problem set. However, if you want to learn more about how the linearization  is derived, check out [section 3.3.1](http://underactuated.csail.mit.edu/underactuated.html?chapter=3) of MIT’s Underactuated Robotics course lecture notes. \n",
    "\n",
    "The dynamics of the cart-pole system are “relatively” simple to derive, compared to other more complicated under-actuated systems. \n",
    "\n",
    "Below is an example matrix linearization of the cart-pole system, derived using the Lagrangian mechanics of the kinetic energy of the cart and the pendulum, as well as the inertia of the pendulum. Matrix A is the state matrix, and B is the input matrix.\n",
    "\n",
    "![](images/linearizedAB.png)\n",
    "\n",
    "The representation of the linear system is then:\n",
    "$ x’ =Ax+Bu $\n",
    "\n",
    "\n",
    "The dynamics of most under-actuated systems are unique to the mechanics of each system. Thus, while it is important to know how to linearize the system by calculating the dynamics, deriving the dynamics is outside the scope of this problem set. Instead, we have taken care of this for you, and pass in the appropriate linearized A and B matrices to the LQR method you will implement below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing LQR (20 points):\n",
    "\n",
    "As our system has been linearized, we can use LQR to solve for the gains matrix K. Recall that LQR finds the optimal solution for a given quadratic cost function by minimizing the value of the cost.  \n",
    "\n",
    "The feedback control law that minimizes the value of the cost (LQR):\n",
    "\n",
    "$u^{*} = - R^{-1} B^T S x = -Kx$\n",
    "\n",
    "Recall that in lecture we talked about the Algebraic Riccati Equation (ARE) that is used to solve for S, which in turn is used to solve for K. \n",
    "\n",
    "Algebraic Ricatti Equation:\n",
    "\n",
    "$0 = SA + A^T S - SBR^{-1}B^T S + Q$\n",
    "\n",
    "Below, you will implement LQR using the given equations. You will most likely find [this API reference](https://docs.scipy.org/doc/scipy-0.19.0/reference/linalg.html) page useful for solving the continuous Algebraic Riccati Equation solution and other linear algebra operations such as computing the inverse or transpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "solve_lqr_fn",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def solve_lqr(A, B, Q, R):\n",
    "    \"\"\"\n",
    "    Solve the continuous time LQR controller\n",
    "    Inputs - A, B, Q, R\n",
    "    A: State matrix\n",
    "    B: Input matrix\n",
    "    Q: The gain of the cost function on the states of the system R matrix\n",
    "    R: gain of the cost function on the input to the system.\n",
    "    Returns - K: Gains matrix\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    S = matrix(scipy.linalg.solve_continuous_are(A, B, Q, R))\n",
    "    K = matrix(scipy.linalg.inv(R)*(B.T*S))\n",
    "    return K\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "check_lqr",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'check_lqr_solver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-87a861f3da29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheck_lqr_solver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolve_lqr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'check_lqr_solver' is not defined"
     ]
    }
   ],
   "source": [
    "check_lqr_solver(solve_lqr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unstable equilibrium state vector of the this system is $u = [x_0, dx_0, \\theta_0, d\\theta_0] = [0, 0, 0, 0]$. Note that $\\theta = 0$ denotes the pole’s upright position relative to the cart’s center of mass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "tune_qr",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## Choosing Q and R Cost Matrices (20 points)\n",
    "\n",
    "Now, we define two Q and R matrices. The Q matrix is the gain of the cost function on the states of the system, while the R matrix is the gain of the cost function on the input to the system. \n",
    "\n",
    "Below, you will fill in valid values for the Q and R matrices. Your Q and R matrices are considered ‘valid’ if they return the cart-pole system back to our final goal state. Remember that our main goal state is the keep the pole upright (theta = 0), and to drive the cart back to it’s initial position (x=0). Additionally, we want our input to be as minimal as possible. Therefore, we will implement these goals into our control system using the Q and R matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "set_qr",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def tuneQandR():\n",
    "    \"\"\"\n",
    "    Tune the Q and R matrices\n",
    "    \"\"\"\n",
    "    Q = matrix([\n",
    "        [1, 0, 0, 0],\n",
    "        [0, 1, 0, 0],\n",
    "        [0, 0, 1, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ])\n",
    "    R = 10\n",
    "    ### BEGIN SOLUTION\n",
    "    # For instance...\n",
    "    Q = matrix([\n",
    "        [100, 0, 0, 0],\n",
    "        [0, 1, 0, 0],\n",
    "        [0, 0, 100, 0],\n",
    "        [0, 0, 0, 1]\n",
    "    ])\n",
    "    R = 6\n",
    "    ### END SOLUTION    \n",
    "    return (Q, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "tune_qr_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-aabee3ea9efd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuneQandR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtune_cost_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-b5871188646a>\u001b[0m in \u001b[0;36mtuneQandR\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mTune\u001b[0m \u001b[0mdifferent\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mof\u001b[0m \u001b[0mQ\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mR\u001b[0m \u001b[0mhere\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[0;32m----> 5\u001b[0;31m     Q = matrix([\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'matrix' is not defined"
     ]
    }
   ],
   "source": [
    "(Q, R) = tuneQandR()\n",
    "tune_cost_functions(Q, R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "threshold_title",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Congratulations! You have now successfully implemented the LQR solver.\n",
    "\n",
    "---\n",
    "## Limitations of LQR (15 points total)\n",
    "\n",
    "Unfortunately, as we use LQR with the linearization of a nonlinear system around a fixed end goal state, LQR is only an optimal policy when the system is already in the range of initial values near the vicinity of the fixed goal state. The range of initial values for which LQR will stabilize the system was introduced in lecture as the basin of attraction. For the cart-pole system, the dimensions of the basin of attraction are all the initial $\\theta$ and $d\\theta$ values for which LQR converges to the goal state.\n",
    "\n",
    "Therefore, LQR works well as a stabilizer for the cart-pole system when the pendulum is at an angle near the top of the cart’s center of mass and has a small enough angular speed, or in other words is inside the basin of attraction. LQR does not converge to the goal state when the pendulum is in a state that is outside the basin of attraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\t<video width=\"620\" height=\"420\" controls>\n",
       "\t  <source src=\"./media/lqr_no_swingup_pi.mp4\" type=\"video/mp4\">\n",
       "\t</video>\n",
       "\t"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_local_video('lqr_no_swingup_pi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this method, you will test the size of LQR’s basin of attraction by varying the initial $\\theta_{init}$ of the system. We will not worry about the $d\\theta$ dimension for this problem. \n",
    "\n",
    "Play with the system as much as you can until you find the highest ${\\pm\\theta_{init}}$ threshold value for which LQR alone is still able to stabilize the system above the cart’s center of mass. We will be using a tolerance to test this problem, so don’t worry too much about finding the exact $\\theta$ value LQR fails at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "set_threshold",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def test_lqr_limits():\n",
    "    \"\"\"\n",
    "    Try different ranges for the initial pendulum angle\n",
    "    outputs: (neg_threshold, pos_threshold)\n",
    "    - pos_threshold: theta initial (in radians)\n",
    "    - neg_threshold: - theta initial\n",
    "    \"\"\"\n",
    "    pos_threshold = pi/2\n",
    "    neg_threshold = -pi/2\n",
    "    \n",
    "    return (neg_threshold, pos_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "test_threshold",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "(neg_threshold, pos_threshold) = test_lqr_limits()\n",
    "test_threshold(neg_threshold, pos_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As LQR fails when the initial state of the system is outside of its basin of attraction, we must instead devise a nonlinear control that is able to drive the system near the unstable equilibrium point that LQR is linearized at. We have already implemented this controller for you, called the “swing-up controller”. The swing-up controller is derived using the energy of pendulum and a linearization of the actuated cart counteracting the dynamic contributions of the pendulum (called the collocated partial feedback linearization). If you’re interested in learning more about the derivation of the swing-up controller, feel free to read [sections 3.4-3.5](http://underactuated.csail.mit.edu/underactuated.html?chapter=3) of the lecture notes.\n",
    "\n",
    "The swing-up is a nonlinear controller that will push all system trajectories to the unstable equilibrium. But does it make the unstable equilibrium locally stable? No. Small perturbations may cause the system to drive all of the way around the circle in order to once again return to the unstable equilibrium, as shown in the video below.\n",
    "%%HTML\n",
    "<video width=\"320\" height=\"240\" controls>\n",
    "  <source src=\".media/no_lqr_dx0-01.mp4\" type=\"video/mp4\">\n",
    "</video>\n",
    "\n",
    "For this reason, once trajectories come into the vicinity of our swing-up controller, we must switch to our LQR balancing controller to complete the task.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "use_swing_up",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In the demo below, we show that even when the initial $\\theta$ values of the system are outside the threshold you found above, the swing-up controller is able to kick in and eventually push the system back into a state inside LQR’s basin of attraction, at which point the system switches to LQR control in order to balance the pendulum at the unstable equilibrium point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "test_with_swing_up",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "simulate_with_swingup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## LQR Trees (30 points total)\n",
    "\n",
    "We learned in lecture that LQR trees are a method of extending the linearized control of underactuated systems. \n",
    "\n",
    "Remember that in the previous section, we showed that LQR is inadequate when the states of the system are outside LQR’s linearized point’s basin of attraction. LQR-trees work around this limitation by linearizing the dynamics of the system around a set of points and running LQR on each of these points to generate a unique K gains matrix for each point. Thus, the basin of attraction of the system grows as each of the linearized points has its own basin of attraction, and the control optimization of each of the points ‘pulls’ the system as a whole to its intended final state.\n",
    "\n",
    "For the following questions, [this paper](http://groups.csail.mit.edu/robotics-center/public_papers/Tedrake09a.pdf) is a useful resource, if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Short answer 1 (10 points):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the cart-pole system were implemented using LQR-trees, how would the basin of attraction compare to the system we implemented? The video below of a the cart-pole implemented using LQR trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/Bzq96V1yN5k\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x1058f8a20>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('Bzq96V1yN5k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "sa_1",
     "locked": false,
     "points": 10,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "[YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short answer 2 (10 points):\n",
    "\n",
    "Would you still need the swing-up controller? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "sa_2",
     "locked": false,
     "points": 10,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "[YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short answer 3 (10 points):\n",
    "\n",
    "What would you expect about the computational difficulty of LQR-trees vs the system we implemented? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "sa_3",
     "locked": false,
     "points": 10,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "[YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
